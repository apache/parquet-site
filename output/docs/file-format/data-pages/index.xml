<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Parquet â€“ Data Pages</title><link>/docs/file-format/data-pages/</link><description>Recent content in Data Pages on Parquet</description><generator>Hugo -- gohugo.io</generator><language>en</language><atom:link href="/docs/file-format/data-pages/index.xml" rel="self" type="application/rss+xml"/><item><title>Docs: Encodings</title><link>/docs/file-format/data-pages/encodings/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>/docs/file-format/data-pages/encodings/</guid><description>
&lt;h3 id="a-nameplainaplain-plain--0">&lt;a name="PLAIN">&lt;/a>Plain: (PLAIN = 0)&lt;/h3>
&lt;p>Supported Types: all&lt;/p>
&lt;p>This is the plain encoding that must be supported for types. It is
intended to be the simplest encoding. Values are encoded back to back.&lt;/p>
&lt;p>The plain encoding is used whenever a more efficient encoding can not be used. It
stores the data in the following format:&lt;/p>
&lt;ul>
&lt;li>BOOLEAN: &lt;a href="/docs/file-format/data-pages/encodings/#RLE">Bit Packed&lt;/a>, LSB first&lt;/li>
&lt;li>INT32: 4 bytes little endian&lt;/li>
&lt;li>INT64: 8 bytes little endian&lt;/li>
&lt;li>INT96: 12 bytes little endian (deprecated)&lt;/li>
&lt;li>FLOAT: 4 bytes IEEE little endian&lt;/li>
&lt;li>DOUBLE: 8 bytes IEEE little endian&lt;/li>
&lt;li>BYTE_ARRAY: length in 4 bytes little endian followed by the bytes contained in the array&lt;/li>
&lt;li>FIXED_LEN_BYTE_ARRAY: the bytes contained in the array&lt;/li>
&lt;/ul>
&lt;p>For native types, this outputs the data as little endian. Floating
point types are encoded in IEEE.&lt;/p>
&lt;p>For the byte array type, it encodes the length as a 4 byte little
endian, followed by the bytes.&lt;/p>
&lt;h3 id="dictionary-encoding-plain_dictionary--2-and-rle_dictionary--8">Dictionary Encoding (PLAIN_DICTIONARY = 2 and RLE_DICTIONARY = 8)&lt;/h3>
&lt;p>The dictionary encoding builds a dictionary of values encountered in a given column. The
dictionary will be stored in a dictionary page per column chunk. The values are stored as integers
using the &lt;a href="/docs/file-format/data-pages/encodings/#RLE">RLE/Bit-Packing Hybrid&lt;/a> encoding. If the dictionary grows too big, whether in size
or number of distinct values, the encoding will fall back to the plain encoding. The dictionary page is
written first, before the data pages of the column chunk.&lt;/p>
&lt;p>Dictionary page format: the entries in the dictionary - in dictionary order - using the &lt;a href="/docs/file-format/data-pages/encodings/#PLAIN">plain&lt;/a> encoding.&lt;/p>
&lt;p>Data page format: the bit width used to encode the entry ids stored as 1 byte (max bit width = 32),
followed by the values encoded using RLE/Bit packed described above (with the given bit width).&lt;/p>
&lt;p>Using the PLAIN_DICTIONARY enum value is deprecated in the Parquet 2.0 specification. Prefer using RLE_DICTIONARY
in a data page and PLAIN in a dictionary page for Parquet 2.0+ files.&lt;/p>
&lt;h3 id="a-namerlearun-length-encoding--bit-packing-hybrid-rle--3">&lt;a name="RLE">&lt;/a>Run Length Encoding / Bit-Packing Hybrid (RLE = 3)&lt;/h3>
&lt;p>This encoding uses a combination of bit-packing and run length encoding to more efficiently store repeated values.&lt;/p>
&lt;p>The grammar for this encoding looks like this, given a fixed bit-width known in advance:&lt;/p>
&lt;pre tabindex="0">&lt;code>rle-bit-packed-hybrid: &amp;lt;length&amp;gt; &amp;lt;encoded-data&amp;gt;
length := length of the &amp;lt;encoded-data&amp;gt; in bytes stored as 4 bytes little endian (unsigned int32)
encoded-data := &amp;lt;run&amp;gt;*
run := &amp;lt;bit-packed-run&amp;gt; | &amp;lt;rle-run&amp;gt;
bit-packed-run := &amp;lt;bit-packed-header&amp;gt; &amp;lt;bit-packed-values&amp;gt;
bit-packed-header := varint-encode(&amp;lt;bit-pack-scaled-run-len&amp;gt; &amp;lt;&amp;lt; 1 | 1)
// we always bit-pack a multiple of 8 values at a time, so we only store the number of values / 8
bit-pack-scaled-run-len := (bit-packed-run-len) / 8
bit-packed-run-len := *see 3 below*
bit-packed-values := *see 1 below*
rle-run := &amp;lt;rle-header&amp;gt; &amp;lt;repeated-value&amp;gt;
rle-header := varint-encode( (rle-run-len) &amp;lt;&amp;lt; 1)
rle-run-len := *see 3 below*
repeated-value := value that is repeated, using a fixed-width of round-up-to-next-byte(bit-width)
&lt;/code>&lt;/pre>&lt;ol>
&lt;li>
&lt;p>The bit-packing here is done in a different order than the one in the &lt;a href="/docs/file-format/data-pages/encodings/#BITPACKED">deprecated bit-packing&lt;/a> encoding.
The values are packed from the least significant bit of each byte to the most significant bit,
though the order of the bits in each value remains in the usual order of most significant to least
significant. For example, to pack the same values as the example in the deprecated encoding above:&lt;/p>
&lt;p>The numbers 1 through 7 using bit width 3:&lt;/p>
&lt;pre tabindex="0">&lt;code>dec value: 0 1 2 3 4 5 6 7
bit value: 000 001 010 011 100 101 110 111
bit label: ABC DEF GHI JKL MNO PQR STU VWX
&lt;/code>&lt;/pre>&lt;p>would be encoded like this where spaces mark byte boundaries (3 bytes):&lt;/p>
&lt;pre tabindex="0">&lt;code>bit value: 10001000 11000110 11111010
bit label: HIDEFABC RMNOJKLG VWXSTUPQ
&lt;/code>&lt;/pre>&lt;p>The reason for this packing order is to have fewer word-boundaries on little-endian hardware
when deserializing more than one byte at at time. This is because 4 bytes can be read into a
32 bit register (or 8 bytes into a 64 bit register) and values can be unpacked just by
shifting and ORing with a mask. (to make this optimization work on a big-endian machine,
you would have to use the ordering used in the &lt;a href="/docs/file-format/data-pages/encodings/#BITPACKED">deprecated bit-packing&lt;/a> encoding)&lt;/p>
&lt;/li>
&lt;li>
&lt;p>varint-encode() is ULEB-128 encoding, see &lt;a href="https://en.wikipedia.org/wiki/LEB128">https://en.wikipedia.org/wiki/LEB128&lt;/a>&lt;/p>
&lt;/li>
&lt;li>
&lt;p>bit-packed-run-len and rle-run-len must be in the range [1, 2&lt;sup>31&lt;/sup> - 1].
This means that a Parquet implementation can always store the run length in a signed
32-bit integer. This length restriction was not part of the Parquet 2.5.0 and earlier
specifications, but longer runs were not readable by the most common Parquet
implementations so, in practice, were not safe for Parquet writers to emit.&lt;/p>
&lt;/li>
&lt;/ol>
&lt;p>Note that the RLE encoding method is only supported for the following types of
data:&lt;/p>
&lt;ul>
&lt;li>Repetition and definition levels&lt;/li>
&lt;li>Dictionary indices&lt;/li>
&lt;li>Boolean values in data pages, as an alternative to PLAIN encoding&lt;/li>
&lt;/ul>
&lt;h3 id="a-namebitpackedabit-packed-deprecated-bit_packed--4">&lt;a name="BITPACKED">&lt;/a>Bit-packed (Deprecated) (BIT_PACKED = 4)&lt;/h3>
&lt;p>This is a bit-packed only encoding, which is deprecated and will be replaced by the &lt;a href="/docs/file-format/data-pages/encodings/#RLE">RLE/bit-packing&lt;/a> hybrid encoding.
Each value is encoded back to back using a fixed width.
There is no padding between values (except for the last byte) which is padded with 0s.
For example, if the max repetition level was 3 (2 bits) and the max definition level as 3
(2 bits), to encode 30 values, we would have 30 * 2 = 60 bits = 8 bytes.&lt;/p>
&lt;p>This implementation is deprecated because the &lt;a href="/docs/file-format/data-pages/encodings/#RLE">RLE/bit-packing&lt;/a> hybrid is a superset of this implementation.
For compatibility reasons, this implementation packs values from the most significant bit to the least significant bit,
which is not the same as the &lt;a href="/docs/file-format/data-pages/encodings/#RLE">RLE/bit-packing&lt;/a> hybrid.&lt;/p>
&lt;p>For example, the numbers 1 through 7 using bit width 3:&lt;/p>
&lt;pre tabindex="0">&lt;code>dec value: 0 1 2 3 4 5 6 7
bit value: 000 001 010 011 100 101 110 111
bit label: ABC DEF GHI JKL MNO PQR STU VWX
&lt;/code>&lt;/pre>&lt;p>would be encoded like this where spaces mark byte boundaries (3 bytes):&lt;/p>
&lt;pre tabindex="0">&lt;code>bit value: 00000101 00111001 01110111
bit label: ABCDEFGH IJKLMNOP QRSTUVWX
&lt;/code>&lt;/pre>&lt;p>Note that the BIT_PACKED encoding method is only supported for encoding
repetition and definition levels.&lt;/p>
&lt;h3 id="a-namedeltaencadelta-encoding-delta_binary_packed--5">&lt;a name="DELTAENC">&lt;/a>Delta Encoding (DELTA_BINARY_PACKED = 5)&lt;/h3>
&lt;p>Supported Types: INT32, INT64&lt;/p>
&lt;p>This encoding is adapted from the Binary packing described in &lt;a href="http://arxiv.org/pdf/1209.2137v5.pdf">&amp;ldquo;Decoding billions of integers per second through vectorization&amp;rdquo;&lt;/a> by D. Lemire and L. Boytsov.&lt;/p>
&lt;p>In delta encoding we make use of variable length integers for storing various numbers (not the deltas themselves). For unsigned values, we use ULEB128, which is the unsigned version of LEB128 (&lt;a href="https://en.wikipedia.org/wiki/LEB128#Unsigned_LEB128)">https://en.wikipedia.org/wiki/LEB128#Unsigned_LEB128)&lt;/a>. For signed values, we use zigzag encoding (&lt;a href="https://developers.google.com/protocol-buffers/docs/encoding#signed-integers">https://developers.google.com/protocol-buffers/docs/encoding#signed-integers&lt;/a>) to map negative values to positive ones and apply ULEB128 on the result.&lt;/p>
&lt;p>Delta encoding consists of a header followed by blocks of delta encoded values binary packed. Each block is made of miniblocks, each of them binary packed with its own bit width.&lt;/p>
&lt;p>The header is defined as follows:&lt;/p>
&lt;pre tabindex="0">&lt;code>&amp;lt;block size in values&amp;gt; &amp;lt;number of miniblocks in a block&amp;gt; &amp;lt;total value count&amp;gt; &amp;lt;first value&amp;gt;
&lt;/code>&lt;/pre>&lt;ul>
&lt;li>the block size is a multiple of 128; it is stored as a ULEB128 int&lt;/li>
&lt;li>the miniblock count per block is a divisor of the block size such that their quotient, the number of values in a miniblock, is a multiple of 32; it is stored as a ULEB128 int&lt;/li>
&lt;li>the total value count is stored as a ULEB128 int&lt;/li>
&lt;li>the first value is stored as a zigzag ULEB128 int&lt;/li>
&lt;/ul>
&lt;p>Each block contains&lt;/p>
&lt;pre tabindex="0">&lt;code>&amp;lt;min delta&amp;gt; &amp;lt;list of bitwidths of miniblocks&amp;gt; &amp;lt;miniblocks&amp;gt;
&lt;/code>&lt;/pre>&lt;ul>
&lt;li>the min delta is a zigzag ULEB128 int (we compute a minimum as we need positive integers for bit packing)&lt;/li>
&lt;li>the bitwidth of each block is stored as a byte&lt;/li>
&lt;li>each miniblock is a list of bit packed ints according to the bit width stored at the begining of the block&lt;/li>
&lt;/ul>
&lt;p>To encode a block, we will:&lt;/p>
&lt;ol>
&lt;li>
&lt;p>Compute the differences between consecutive elements. For the first element in the block, use the last element in the previous block or, in the case of the first block, use the first value of the whole sequence, stored in the header.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Compute the frame of reference (the minimum of the deltas in the block). Subtract this min delta from all deltas in the block. This guarantees that all values are non-negative.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Encode the frame of reference (min delta) as a zigzag ULEB128 int followed by the bit widths of the miniblocks and the delta values (minus the min delta) bit packed per miniblock.&lt;/p>
&lt;/li>
&lt;/ol>
&lt;p>Having multiple blocks allows us to adapt to changes in the data by changing the frame of reference (the min delta) which can result in smaller values after the subtraction which, again, means we can store them with a lower bit width.&lt;/p>
&lt;p>If there are not enough values to fill the last miniblock, we pad the miniblock so that its length is always the number of values in a full miniblock multiplied by the bit width. The values of the padding bits should be zero, but readers must accept paddings consisting of arbitrary bits as well.&lt;/p>
&lt;p>If, in the last block, less than &lt;code>&amp;lt;number of miniblocks in a block&amp;gt;&lt;/code> miniblocks are needed to store the values, the bytes storing the bit widths of the unneeded miniblocks are still present, their value should be zero, but readers must accept arbitrary values as well. There are no additional padding bytes for the miniblock bodies though, as if their bit widths were 0 (regardless of the actual byte values). The reader knows when to stop reading by keeping track of the number of values read.&lt;/p>
&lt;p>The following examples use 8 as the block size to keep the examples short, but in real cases it would be invalid.&lt;/p>
&lt;h4 id="example-1">Example 1&lt;/h4>
&lt;p>1, 2, 3, 4, 5&lt;/p>
&lt;p>After step 1), we compute the deltas as:&lt;/p>
&lt;p>1, 1, 1, 1&lt;/p>
&lt;p>The minimum delta is 1 and after step 2, the deltas become&lt;/p>
&lt;p>0, 0, 0, 0&lt;/p>
&lt;p>The final encoded data is:&lt;/p>
&lt;p>header:
8 (block size), 1 (miniblock count), 5 (value count), 1 (first value)&lt;/p>
&lt;p>block
1 (minimum delta), 0 (bitwidth), (no data needed for bitwidth 0)&lt;/p>
&lt;h4 id="example-2">Example 2&lt;/h4>
&lt;p>7, 5, 3, 1, 2, 3, 4, 5, the deltas would be&lt;/p>
&lt;p>-2, -2, -2, 1, 1, 1, 1&lt;/p>
&lt;p>The minimum is -2, so the relative deltas are:&lt;/p>
&lt;p>0, 0, 0, 3, 3, 3, 3&lt;/p>
&lt;p>The encoded data is&lt;/p>
&lt;p>header:
8 (block size), 1 (miniblock count), 8 (value count), 7 (first value)&lt;/p>
&lt;p>block
-2 (minimum delta), 2 (bitwidth), 00000011111111b (0,0,0,3,3,3,3 packed on 2 bits)&lt;/p>
&lt;h4 id="characteristics">Characteristics&lt;/h4>
&lt;p>This encoding is similar to the &lt;a href="/docs/file-format/data-pages/encodings/#RLE">RLE/bit-packing&lt;/a> encoding. However the &lt;a href="/docs/file-format/data-pages/encodings/#RLE">RLE/bit-packing&lt;/a> encoding is specifically used when the range of ints is small over the entire page, as is true of repetition and definition levels. It uses a single bit width for the whole page.
The delta encoding algorithm described above stores a bit width per miniblock and is less sensitive to variations in the size of encoded integers. It is also somewhat doing RLE encoding as a block containing all the same values will be bit packed to a zero bit width thus being only a header.&lt;/p>
&lt;h3 id="delta-length-byte-array-delta_length_byte_array--6">Delta-length byte array: (DELTA_LENGTH_BYTE_ARRAY = 6)&lt;/h3>
&lt;p>Supported Types: BYTE_ARRAY&lt;/p>
&lt;p>This encoding is always preferred over PLAIN for byte array columns.&lt;/p>
&lt;p>For this encoding, we will take all the byte array lengths and encode them using delta
encoding (DELTA_BINARY_PACKED). The byte array data follows all of the length data just
concatenated back to back. The expected savings is from the cost of encoding the lengths
and possibly better compression in the data (it is no longer interleaved with the lengths).&lt;/p>
&lt;p>The data stream looks like:&lt;/p>
&lt;p>&lt;Delta Encoded Lengths> &lt;Byte Array Data>&lt;/p>
&lt;p>For example, if the data was &amp;ldquo;Hello&amp;rdquo;, &amp;ldquo;World&amp;rdquo;, &amp;ldquo;Foobar&amp;rdquo;, &amp;ldquo;ABCDEF&amp;rdquo;:&lt;/p>
&lt;p>The encoded data would be DeltaEncoding(5, 5, 6, 6) &amp;ldquo;HelloWorldFoobarABCDEF&amp;rdquo;&lt;/p>
&lt;h3 id="delta-strings-delta_byte_array--7">Delta Strings: (DELTA_BYTE_ARRAY = 7)&lt;/h3>
&lt;p>Supported Types: BYTE_ARRAY&lt;/p>
&lt;p>This is also known as incremental encoding or front compression: for each element in a
sequence of strings, store the prefix length of the previous entry plus the suffix.&lt;/p>
&lt;p>For a longer description, see &lt;a href="https://en.wikipedia.org/wiki/Incremental_encoding">https://en.wikipedia.org/wiki/Incremental_encoding&lt;/a>.&lt;/p>
&lt;p>This is stored as a sequence of delta-encoded prefix lengths (DELTA_BINARY_PACKED), followed by
the suffixes encoded as delta length byte arrays (DELTA_LENGTH_BYTE_ARRAY).&lt;/p>
&lt;h3 id="byte-stream-split-byte_stream_split--9">Byte Stream Split: (BYTE_STREAM_SPLIT = 9)&lt;/h3>
&lt;p>Supported Types: FLOAT DOUBLE&lt;/p>
&lt;p>This encoding does not reduce the size of the data but can lead to a significantly better
compression ratio and speed when a compression algorithm is used afterwards.&lt;/p>
&lt;p>This encoding creates K byte-streams of length N where K is the size in bytes of the data
type and N is the number of elements in the data sequence.
The bytes of each value are scattered to the corresponding streams. The 0-th byte goes to the
0-th stream, the 1-st byte goes to the 1-st stream and so on.
The streams are concatenated in the following order: 0-th stream, 1-st stream, etc.&lt;/p>
&lt;p>Example:
Original data is three 32-bit floats and for simplicity we look at their raw representation.&lt;/p>
&lt;pre tabindex="0">&lt;code> Element 0 Element 1 Element 2
Bytes AA BB CC DD 00 11 22 33 A3 B4 C5 D6
&lt;/code>&lt;/pre>&lt;p>After applying the transformation, the data has the following representation:&lt;/p>
&lt;pre tabindex="0">&lt;code>Bytes AA 00 A3 BB 11 B4 CC 22 C5 DD 33 D6
&lt;/code>&lt;/pre></description></item><item><title>Docs: Checksumming</title><link>/docs/file-format/data-pages/checksumming/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>/docs/file-format/data-pages/checksumming/</guid><description>
&lt;p>Column chunks are composed of pages written back to back. The pages share a common header and readers can skip over page they are not interested in. The data for the page follows the header and can be compressed and/or encoded. The compression and encoding is specified in the page metadata.&lt;/p></description></item><item><title>Docs: Column Chunks</title><link>/docs/file-format/data-pages/columnchunks/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>/docs/file-format/data-pages/columnchunks/</guid><description>
&lt;p>Column chunks are composed of pages written back to back. The pages share a common header and readers can skip over page they are not interested in. The data for the page follows the header and can be compressed and/or encoded. The compression and encoding is specified in the page metadata.&lt;/p></description></item><item><title>Docs: Error Recovery</title><link>/docs/file-format/data-pages/errorrecovery/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>/docs/file-format/data-pages/errorrecovery/</guid><description>
&lt;p>If the file metadata is corrupt, the file is lost. If the column metadata is corrupt, that column chunk is lost (but column chunks for this column in other row groups are okay). If a page header is corrupt, the remaining pages in that chunk are lost. If the data within a page is corrupt, that page is lost. The file will be more resilient to corruption with smaller row groups.&lt;/p>
&lt;p>Potential extension: With smaller row groups, the biggest issue is placing the file metadata at the end. If an error happens while writing the file metadata, all the data written will be unreadable. This can be fixed by writing the file metadata every Nth row group. Each file metadata would be cumulative and include all the row groups written so far. Combining this with the strategy used for orc or avro files using sync markers, a reader could recover partially written files.&lt;/p></description></item></channel></rss>